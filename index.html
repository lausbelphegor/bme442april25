<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>Decoding Visual Recognition of Objects from EEG Signals based on the EEG-Conformer Model</title>
		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section>
					<h2>Decoding Visual Recognition of Objects from EEG Signals based on the EEG-Conformer Model</h2>
				</section>
				<section>
					<h2>Project Aim</h2>
					<p>To predict objects based on the eeg signals of the subject</p>
				</section>
				<section>
					<section>
						<h2>Dataset Overview</h2>
						<p>Data from 50 subjects viewing images, recording EEG responses.</p>
						<p><small><a href="https://openneuro.org/datasets/ds003825/versions/1.2.0">Data Link</a></small></p>
					</section>
					<section>
						<img src=".\public\images\data1.png" alt="EEG" style="width: 50%;">
						<p><small><a href="https://osf.io/b7ve9">Object Concepts Metadata</a></small></p>
					</section>
					<section>
						<img src=".\public\images\example_sequence.gif" alt="EEG" style="width: 100%;">
					</section>
				</section>
				<section>
						<h2>System Input and Output</h2>
						<p>Input: EEG signals from 64 electrodes, downsampled at 250Hz.</p>
						<p>Output: Object prediction from 1,854 image concepts.</p>
				</section>
				<section>
					<section>
						<h2>Neural Network Architecture</h2>
						<p><small><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9991178">Proposed Model</a></small></p>
					</section>
					<section>
						<small>
							<ul>
								<li>EEG Input</li>
								<li> Convolutional Layers
									<ul> 
										<li>Temporal: Capturing temporal dependencies in the eeg signal</li>
										<li>Spatial: Capturing spatial dependencies between electrodes</li>
									</ul>
								</li>
								<li>Avg. Pooling</li>
								<li>Tokenization: 2D-to-Seq</li>
								<li>Linear Layer Before Self-Attention</li>
								<li>N x Self-Attention
									<ul> 
										<li>Q (Query), K (Key), V (Value) matrices</li>
										<li>Dot Product</li>
										<li>Scaling</li>
										<li>Softmax</li>
										<li>Feed-Forward</li>
									</ul>
								</li>
								<li>Classifier</li>
							</ul>
						</small>
					</section>
					<section>
						<img src=".\public\images\eegconformer.png" alt="EEG" style="width: 100%;">
					</section>
				</section>
				<section>
					<h2>Related Work</h2>
					<small>
					<p><a href="https://arxiv.org/pdf/2008.12490.pdf">Decoding Visual Recognition of Objects from EEG Signals based on Attention-Driven Convolutional Neural Network</a></p>
					<p><a href="https://www.sciencedirect.com/science/article/abs/pii/S1746809421005930">Deep learning helps EEG signals predict different stages of visual processing in the human brain</a></p>
					<p><a href="https://arxiv.org/pdf/2209.13090.pdf">EEG-based Image Feature Extraction for Visual Classification using Deep Learning</a></p>
					</small>
				</section>
			</div>
		</div>
		<style>
			.container{
				display: flex;
			}
			.col{
				flex: 1;
			}
		</style>
		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script src="plugin/math/math.js"></script>
		<script>
			Reveal.initialize({
				hash: true,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});
		</script>
	</body>
</html>
